{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dl_predicting_house_prices.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNtYFRnZJ70stl7Y+0pZTjZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"pna2IqvqGNYp"},"source":["from tensorflow.keras.datasets import boston_housing\n","\n","(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYhGuMMWGdnD"},"source":[" print(train_data.shape)\n"," print(test_data.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"teHjSzv_Gjid"},"source":["train_targets[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q73Qohn8IBhv"},"source":["CRIM - per capita crime rate by town\n","\n","ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n","\n","INDUS - proportion of non-retail business acres per town.\n","\n","CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n","\n","NOX - nitric oxides concentration (parts per 10 million)\n","\n","RM - average number of rooms per dwelling\n","\n","AGE - proportion of owner-occupied units built prior to 1940\n","\n","DIS - weighted distances to five Boston employment centres\n","\n","RAD - index of accessibility to radial highways\n","\n","TAX - full-value property-tax rate per $10,000\n","\n","PTRATIO - pupil-teacher ratio by town\n","\n","B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n","\n","LSTAT - % lower status of the population"]},{"cell_type":"code","metadata":{"id":"0zsEhSSlICnt"},"source":["mean = train_data.mean(axis=0)\n","train_data -= mean\n","\n","std = train_data.std(axis=0)\n","train_data /= std\n","\n","train_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aJF2rB75Lv3k"},"source":["테스트 데이터 정규화 시 사용한 값이 훈련 데이터에서 계산한 값임을 유의."]},{"cell_type":"code","metadata":{"id":"fj-Lpd9SLQzO"},"source":["from keras import models\n","from keras import layers\n","\n","def build_model():\n","    model = models.Sequential()\n","    model.add(layers.Dense(64, activation='relu',\n","                           input_shape=(train_data.shape[1],)))\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(1))\n","    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BFaNS-FL1Jg"},"source":["import numpy as np\n","\n","k = 4\n","\n","num_val_samples = len(train_data) // 4\n","num_epochs = 100\n","all_scores = []\n","\n","for i in range(k):\n","    print('처리중인 폴드 #',i)\n","    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n","    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n","\n","    partial_train_data = np.concatenate(\n","        [train_data[:i * num_val_samples],\n","         train_data[(i+1) * num_val_samples:]],\n","         axis=0)\n","    \n","    partial_train_targets = np.concatenate(\n","        [train_targets[:i * num_val_samples],\n","         train_targets[(i+1) * num_val_samples:]],\n","         axis=0)\n","    \n","    model = build_model()\n","    model.fit(partial_train_data, partial_train_targets,\n","              epochs = num_epochs, batch_size=1, verbose=0)\n","    \n","    val_mse , val_mae = model.evaluate(val_data, val_targets, verbose=0)\n","    all_scores.append(val_mae)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CYw4m9foNQHX"},"source":["all_scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bkUcPT2POVk8"},"source":["np.mean(all_scores)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HBUT0FzPS3A7"},"source":["num_epochs = 500\n","all_mae_histories = []\n","\n","for i in range(k):\n","    print('처리중인 폴드 #',i)\n","    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n","    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n","\n","    partial_train_data = np.concatenate(\n","        [train_data[:i * num_val_samples],\n","         train_data[(i+1) * num_val_samples:]],\n","         axis=0)\n","    \n","    partial_train_targets = np.concatenate(\n","        [train_targets[:i * num_val_samples],\n","         train_targets[(i+1) * num_val_samples:]],\n","         axis=0)\n","    \n","    model = build_model()\n","\n","    history = model.fit(partial_train_data, partial_train_targets,\n","                        validation_data = (val_data, val_targets),\n","                        epochs = num_epochs, batch_size=1, verbose=0)\n","    \n","    mae_history = history.history['val_mae']\n","    all_mae_histories.append(mae_history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sz30wYThTiJn"},"source":["avg_mae_history = [\n","                   np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XvP2vxJeGIE"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(range(1,len(avg_mae_history)+1), avg_mae_history)\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation MAE')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sIp-EfohNhMu"},"source":["def smooth_curve(points, factor=0.9):\n","    smoothed_points = []\n","    for point in points:\n","        if smoothed_points:\n","            previous = smoothed_points[-1]\n","            smoothed_points.append(previous * factor + point * (1-factor))\n","\n","        else:\n","            smoothed_points.append(point)\n","\n","    return smoothed_points\n","\n","smooth_mae_history = smooth_curve(mae_history[10:])\n","\n","plt.plot(range(1, len(smooth_mae_history)+1) , smooth_mae_history)\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation MAE')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_DFC62fVfGP"},"source":["model = build_model()\n","\n","model.fit(train_data, train_targets,\n","          epochs = 80, batch_size=16, verbose=0)\n","\n","test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTpUC9XDWG9K"},"source":["test_mae_score"],"execution_count":null,"outputs":[]}]}