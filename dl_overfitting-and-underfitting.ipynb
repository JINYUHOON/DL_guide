{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dl_overfitting-and-underfitting.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMLg37OcNmhdfckcuvBMznj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"eTUXiAhoO2le"},"source":["from tensorflow.keras.datasets import imdb\n","import numpy as np\n","\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n","\n","def vectorize_sequences(sequences, dimension=10000):\n","    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n","    results = np.zeros((len(sequences), dimension))\n","    for i, sequence in enumerate(sequences):\n","        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n","    return results\n","\n","# 훈련 데이터를 벡터로 변환합니다\n","x_train = vectorize_sequences(train_data)\n","# 테스트 데이터를 벡터로 변환합니다\n","x_test = vectorize_sequences(test_data)\n","# 레이블을 벡터로 변환합니다\n","y_train = np.asarray(train_labels).astype('float32')\n","y_test = np.asarray(test_labels).astype('float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XSAsj7fmQEFc"},"source":["from tensorflow.keras import models\n","from tensorflow.keras import layers\n","\n","model = models.Sequential()\n","model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n","model.add(layers.Dense(16, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","\n","model.compile(optimizer='rmsprop',\n","              loss='binary_crossentropy',\n","              metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTFHm6VcQ4yD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBsrpsmuQiqa"},"source":["from tensorflow.keras import models\n","from tensorflow.keras import layers\n","\n","smodel = models.Sequential()\n","smodel.add(layers.Dense(6, activation='relu', input_shape=(10000,)))\n","smodel.add(layers.Dense(6, activation='relu'))\n","smodel.add(layers.Dense(1, activation='sigmoid'))\n","\n","\n","smodel.compile(optimizer='rmsprop',\n","              loss='binary_crossentropy',\n","              metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70KTCL_2RYbn"},"source":["history = model.fit(x_train, y_train,\n","                    epochs=20,\n","                    batch_size=512,\n","                    validation_data=(x_test,y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fv4Ff9hOSHPh"},"source":["shistory = smodel.fit(x_train, y_train,\n","                    epochs=20,\n","                    batch_size=512,\n","                    validation_data=(x_test,y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0ofAXazSTxx"},"source":["epochs = range(1,21)\n","\n","original_val_loss = history.history['val_loss']\n","s_val_loss = shistory.history['val_loss']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"moRPUIP6S1T1"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(epochs, original_val_loss, 'b+',label='Original')\n","plt.plot(epochs, s_val_loss, 'o', label='Smaller')\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4uGu1XQhTYHj"},"source":["big_model = models.Sequential()\n","big_model.add(layers.Dense(1024, activation='relu', input_shape=(10000,)))\n","big_model.add(layers.Dense(1024, activation='relu'))\n","big_model.add(layers.Dense(1, activation='sigmoid'))\n","\n","\n","big_model.compile(optimizer='rmsprop',\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","\n","big_history = big_model.fit(x_train, y_train,\n","                            epochs = 20,\n","                            batch_size = 512,\n","                            validation_data=(x_test,y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jvBe0giUDT_"},"source":["epochs = range(1,21)\n","\n","original_val_loss = history.history['val_loss']\n","s_val_loss = shistory.history['val_loss']\n","big_val_loss = big_history.history['val_loss']\n","\n","import matplotlib.pyplot as plt\n","\n","plt.plot(epochs, original_val_loss, 'b+',label='Original')\n","plt.plot(epochs, s_val_loss, 'o', label='Smaller')\n","plt.plot(epochs, big_val_loss, 'x', color='r', label='Big')\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iyEWv1oIXL8J"},"source":["original_loss = history.history['loss']\n","s_loss = shistory.history['loss']\n","big_loss = big_history.history['loss']\n","\n","import matplotlib.pyplot as plt\n","\n","plt.plot(epochs, original_loss, 'b+',label='Original')\n","plt.plot(epochs, s_loss, 'o', label='Smaller')\n","plt.plot(epochs, big_loss, 'x', color='r', label='Big')\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"traJ5ViTa72B"},"source":["용량이 큰 네트워크는 훈련 손실이 빠르게 0에 가까워진다. 용량이 많은 네트워크일수록 더 빠르게 훈련 데이터를 모델링 할 수 있어서 훈련 손실이\n","낮아진다. 하지만 더욱 과대적합에 민감해진다. (훈련과 검증 손실 사이에 큰 차이가 발생.)"]},{"cell_type":"code","metadata":{"id":"lZYoINxBXL_R"},"source":["from tensorflow.keras import regularizers\n","\n","l2_model = models.Sequential()\n","l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n","                          activation='relu',\n","                          input_shape=(10000,)))\n","l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n","                          activation='relu'))\n","l2_model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKHzphSWdk21"},"source":["l2_model.compile(optimizer='rmsprop',\n","                 loss='binary_crossentropy',\n","                 metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o2SYhz63d2jY"},"source":["l2_model_hist = l2_model.fit(x_train, y_train,\n","                             epochs = 20,\n","                             batch_size=512,\n","                             validation_data=(x_test,y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEprzZLSeVeG"},"source":["l2_model_val_loss = l2_model_hist.history['val_loss']\n","\n","epochs = range(1,21)\n","\n","plt.plot(epochs, original_val_loss, 'b+',label='Original')\n","plt.plot(epochs, l2_model_val_loss, 'o', label='L2-regularized model' )\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_q5wRJbNfFfd"},"source":["두 모댈이 동일한 파라미터 수를 가지고 있더라도 L2 규제를 사용한 모델이 기본 모델 보다 훨씬 더 과대적합에 잘 견디고 있음"]},{"cell_type":"markdown","metadata":{"id":"kOPsi2r2fXPL"},"source":["# 과제\n","L1 (alpha=0.001) 모델과 비교"]},{"cell_type":"code","metadata":{"id":"uLQfLBXNffQs"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oSnDtx3ahb17"},"source":["dpt_model = models.Sequential()\n","dpt_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n","dpt_model.add(layers.Dropout(0.5))\n","dpt_model.add(layers.Dense(16, activation='relu'))\n","dpt_model.add(layers.Dropout(0.5))\n","dpt_model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oaEjMDSsh5Qq"},"source":["dpt_model.compile(optimizer='rmsprop',\n","                  loss = 'binary_crossentropy',\n","                  metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6gws0aLYiNP3"},"source":["dpt_history = dpt_model.fit(x_train, y_train,\n","                            epochs=20,\n","                            batch_size=512,\n","                            validation_data=(x_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0mek4Elbidp-"},"source":["dpt_model_val_loss = dpt_history.history['val_loss']\n","\n","epochs = range(1,21)\n","\n","plt.plot(epochs, original_val_loss, 'b+',label='Original')\n","plt.plot(epochs, dpt_model_val_loss, 'o', label='L2-regularized model' )\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5nBQejO6jJW7"},"source":["신경망에서 과대적합을 방지하기 위한 방법\n","\n","- 훈련 데이터를 더 모은다.\n","- 네트워크의 용량을 감소 시킨다\n","- 가중치 규제를 추가한다.\n","- 드롭아웃을 추가한다."]},{"cell_type":"code","metadata":{"id":"kCNKPEu0jSZ2"},"source":[""],"execution_count":null,"outputs":[]}]}